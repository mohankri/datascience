library(XML)
source('~/datascience/rday/webcrawler.R')
source('~/datascience/rday/webcrawler.R')
names(ds.skaters) <- tolower(colnames(ds.skaters))
for(i in 1:ncol(ds.skaters)) {
ds.skaters[,i] <- as.character(ds.skaters[,i])
names(ds.skaters) <- tolower(colnames(ds.skaters))
}
URL <- paste("http://www.hockey-reference.com/leagues/NHL_", S, "_skaters.html", sep="")
tables <- readHTMLTable(URL)
ds.skaters <- tables$stats
for(i in 1:ncol(ds.skaters)) {
ds.skaters[,i] <- as.character(ds.skaters[,i])
names(ds.skaters) <- tolower(colnames(ds.skaters))
}
colnames(ds.skaters)
names(ds.skaters)[10] <- "plusmin"
names(ds.skaters)[17] <- "spct"
for(i in c(1, 3, 6:18)) {
ds.skaters[,i] <- as.numeric(ds.skaters[, i])
}
ds.skaters$seconds <- (ds.skaters$toi*60)/ds.skaters$gp
ds.skaters <- ds.skaters[!is.na(ds.skaters$rk), ]
ds.skaters <- ds.skaters[ds.skaters$tm != "TOT", ]
ds.skaters$season <- S
return(ds.skaters)
GrabSkaters <- function(S) {
# The function takes parameter S which is a string and represents the Season
# Returns: data frame
## create the URL
URL <- paste("http://www.hockey-reference.com/leagues/NHL_", S, "_skaters.html", sep="")
## grab the page -- the table is parsed nicely
tables <- readHTMLTable(URL)
ds.skaters <- tables$stats
## determine if the HTML table was well formed (column names are the first record)
## can either read in directly or need to force column names
## and
## I don't like dealing with factors if I don't have to
## and I prefer lower case
for(i in 1:ncol(ds.skaters)) {
ds.skaters[,i] <- as.character(ds.skaters[,i])
names(ds.skaters) <- tolower(colnames(ds.skaters))
}
## fix a couple of the column names
colnames(ds.skaters)
names(ds.skaters)[10] <- "plusmin"
names(ds.skaters)[17] <- "spct"
## finally fix the columns - NAs forced by coercion warnings
for(i in c(1, 3, 6:18)) {
ds.skaters[,i] <- as.numeric(ds.skaters[, i])
}
## convert toi to seconds, and seconds/game
ds.skaters$seconds <- (ds.skaters$toi*60)/ds.skaters$gp
## remove the header and totals row
ds.skaters <- ds.skaters[!is.na(ds.skaters$rk), ]
ds.skaters <- ds.skaters[ds.skaters$tm != "TOT", ]
## add the year
ds.skaters$season <- S
## return the dataframe
return(ds.skaters)
}
SEASON <- as.character(c(1960:2004, 2006:2011))
dataset <- data.frame()
for (S in SEASON) {
temp <- GrabSkaters(S)
dataset <- rbind(dataset, temp)
print(paste("Completed Season ", S, sep=""))
## pause the script so we don't kill their servers
Sys.sleep(3)
}
write.table(dataset, "Historical Skater Stats.csv", sep=",",
row.names=F)
source('~/datascience/rday/webcrawler.R')
URL <- paste("http://www.hockey-reference.com/leagues/NHL_", S, "_skaters.html", sep="")
tables <- readHTMLTable(URL)
ds.skaters
for(i in 1:ncol(ds.skaters)) {
ds.skaters[,i] <- as.character(ds.skaters[,i])
names(ds.skaters) <- tolower(colnames(ds.skaters))
}
colnames(ds.skaters)
ds.skaters[,i] <- as.numeric(ds.skaters[, i])
ds.skaters$seconds <- (ds.skaters$toi*60)/ds.skaters$gp
library(ggplot2)
library(ggplot2)
install.packages(ggplot2)
"ggplot2"
install.packages("ggplot2")
library(ggplot2)
diamonds
diamonds
tbl_df(diamonds)
library(dplyr)
install.packages("dplyr")
library(dplyr)
tbl_df(diamonds)
tbl_df(diamonds)
View(diamonds)
diamonds$x %>%
mean()
diamonds$x %>%
round(2) %>%
mean()
install.packages("devtools")
devtools::install_github("rstudio/EDAWR")
library(EDAWR)
storms
cases
population
storms$storm
cases$country
storms$pressure / storms$wind
install.packages("tidlyr")
install.packages("tidyr")
cases
gather(cases, "year", "n", 2:4)
gather(cases, "year", "n", 2:4)
library(tidyr)
gather(cases, "year", "n", 2:4)
pollution
spread(pollution, size, amount)
storms
select(storms, wind, date)
filter(storms, wind >=50)
arrange(storms, wind)
storms %>%
filter(wind >= 50) %>%
select(pressure, date)
population %>% group_by(city)
cities
tb
tb %>% group_by(country)
tb %>% group_by(country, year)
tb %>% group_by(country, year) %>% summarize(cases=sum(cases))
tb
library(EDAWR)
tb
tb %>% group_by(country, year) %>% summarise(cases=sum(sex))
tb %>% group_by(country, year) %>% summarise(cases=sum(child))
install.packages("hflights")
library(dplyr)
library(hflights)
#explore data
data(hflights)
head(hflights)
flights <- tbl_df(hflights)
flights
hflights
data("hflights")
head(hflights)
flights
flights <- tbl_df(hflights)
#flights
print(flights, n=20)
data.frame(head(flights))
flights[flights$Month==2 & flights$DayofMonth==1, ]
filter(flights, Month==1, DayOfMonth==1)
filter(flights, Month==1, DayofMonth ==1)
flights[flights$Month==2 & flights$DayofMonth==1, ]
filter(fights, uniqueCarrier=="AA" | uniqueCarrier=="UA")
filter(flights, uniqueCarrier=="AA" | uniqueCarrier=="UA")
filter(flights, UniqueCarrier=="AA" | UniqueCarrier=="UA")
select(flights, DepTime, ArrTime, FlightNum)
select(flights, Year:DayOfMonth, contains("Taxi"), contains("Delay"))
select(flights, Year:DayofMonth, contains("Taxi"), contains("Delay"))
filter(select(flights, UniqueCarrier, DepDelay), DepDelay > 60)
```{r results='hide'}
```{r results='hide'}
flights[order(flights$DepDelay), c("UniqueCarrier", "DepDelay")]
flights %>%
select("UniqueCarrier", "DepDelay") %>%
arrange(desc(DepDelay))
flights %>%
select(UniqueCarrier, DepDelay) %>%
arrange(desc(DepDelay))
flights$Speed <- flights$Distance / flights$AirTime*60
flights[, c("Distance", "AirTime", "Speed")]
rm(flights)
install(nycflights13)
install.packages(nycflights13)
library(nycflights)
library(nycflights13)
install.packages("nycflights13")
rm(flights)
supressMessages(library(nycflights13))
rm(flights)
suppressMessages(library(nycflights13))
flights
data_frame(a=1:6, b = a*2, c="string", "d+e"=1) %>% glimpse()
library(readr)
refine_original <- read_csv("~/datascience/springboard/datawrangling/refine_original.csv")
View(refine_original)
source('~/datascience/springboard/datawrangling/exercise1.R')
source('~/datascience/springboard/datawrangling/exercise1.R')
source('~/datascience/springboard/datawrangling/exercise1.R')
?regexpr
install.packages("gridExtra")
install.packages("grid")
multiplot
?multiplot
multiplot(p1, p2, p3)
ggplot2::multiplot(p1, p2, p2)
ggplot2::multiplot(p1, p2, p2, cols=2)
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
?predict
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
rm(p)
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
source('~/datascience/rday/modeling.R')
