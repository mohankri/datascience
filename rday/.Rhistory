library(XML)
source('~/datascience/rday/webcrawler.R')
source('~/datascience/rday/webcrawler.R')
names(ds.skaters) <- tolower(colnames(ds.skaters))
for(i in 1:ncol(ds.skaters)) {
ds.skaters[,i] <- as.character(ds.skaters[,i])
names(ds.skaters) <- tolower(colnames(ds.skaters))
}
URL <- paste("http://www.hockey-reference.com/leagues/NHL_", S, "_skaters.html", sep="")
tables <- readHTMLTable(URL)
ds.skaters <- tables$stats
for(i in 1:ncol(ds.skaters)) {
ds.skaters[,i] <- as.character(ds.skaters[,i])
names(ds.skaters) <- tolower(colnames(ds.skaters))
}
colnames(ds.skaters)
names(ds.skaters)[10] <- "plusmin"
names(ds.skaters)[17] <- "spct"
for(i in c(1, 3, 6:18)) {
ds.skaters[,i] <- as.numeric(ds.skaters[, i])
}
ds.skaters$seconds <- (ds.skaters$toi*60)/ds.skaters$gp
ds.skaters <- ds.skaters[!is.na(ds.skaters$rk), ]
ds.skaters <- ds.skaters[ds.skaters$tm != "TOT", ]
ds.skaters$season <- S
return(ds.skaters)
GrabSkaters <- function(S) {
# The function takes parameter S which is a string and represents the Season
# Returns: data frame
## create the URL
URL <- paste("http://www.hockey-reference.com/leagues/NHL_", S, "_skaters.html", sep="")
## grab the page -- the table is parsed nicely
tables <- readHTMLTable(URL)
ds.skaters <- tables$stats
## determine if the HTML table was well formed (column names are the first record)
## can either read in directly or need to force column names
## and
## I don't like dealing with factors if I don't have to
## and I prefer lower case
for(i in 1:ncol(ds.skaters)) {
ds.skaters[,i] <- as.character(ds.skaters[,i])
names(ds.skaters) <- tolower(colnames(ds.skaters))
}
## fix a couple of the column names
colnames(ds.skaters)
names(ds.skaters)[10] <- "plusmin"
names(ds.skaters)[17] <- "spct"
## finally fix the columns - NAs forced by coercion warnings
for(i in c(1, 3, 6:18)) {
ds.skaters[,i] <- as.numeric(ds.skaters[, i])
}
## convert toi to seconds, and seconds/game
ds.skaters$seconds <- (ds.skaters$toi*60)/ds.skaters$gp
## remove the header and totals row
ds.skaters <- ds.skaters[!is.na(ds.skaters$rk), ]
ds.skaters <- ds.skaters[ds.skaters$tm != "TOT", ]
## add the year
ds.skaters$season <- S
## return the dataframe
return(ds.skaters)
}
SEASON <- as.character(c(1960:2004, 2006:2011))
dataset <- data.frame()
for (S in SEASON) {
temp <- GrabSkaters(S)
dataset <- rbind(dataset, temp)
print(paste("Completed Season ", S, sep=""))
## pause the script so we don't kill their servers
Sys.sleep(3)
}
write.table(dataset, "Historical Skater Stats.csv", sep=",",
row.names=F)
source('~/datascience/rday/webcrawler.R')
URL <- paste("http://www.hockey-reference.com/leagues/NHL_", S, "_skaters.html", sep="")
tables <- readHTMLTable(URL)
ds.skaters
for(i in 1:ncol(ds.skaters)) {
ds.skaters[,i] <- as.character(ds.skaters[,i])
names(ds.skaters) <- tolower(colnames(ds.skaters))
}
colnames(ds.skaters)
ds.skaters[,i] <- as.numeric(ds.skaters[, i])
ds.skaters$seconds <- (ds.skaters$toi*60)/ds.skaters$gp
?list
?list.files
print(files)
source('~/datascience/rday/DirList.R')
source('~/datascience/rday/DirList.R')
DIR <- "./"
setwd(DIR)
getwd
list.files("./csv_files")
source('~/datascience/rday/DirList.R')
file<-list.files("./csv_files/")
file<-list.files(R.home())
file
file<-list.files("./csv_files/")
file<-list.files(DIR)
file
source('~/datascience/rday/DirList.R')
source('~/datascience/rday/DirList.R')
source('~/datascience/rday/DirList.R')
print(paste(DIR, "./csv_files/",sep=""))
source('~/datascience/rday/DirList.R')
file<-list.files(paste(DIR, "./csv_files/",sep=""))
source('~/datascience/rday/DirList.R')
print(file)
source('~/datascience/rday/DirList.R')
